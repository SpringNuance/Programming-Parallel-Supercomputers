{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 types of MPI names\n",
    "\n",
    "- Datatype: such as MPI_Info, MPI_Win. It is MPI_ followed by a noun with first capitalized letter\n",
    "- Function: such as MPI_Init, MPI_Send. It is MPI_ followed by a verb with first capitalized letter\n",
    "- Constant: such as MPI_COMM_WORLD, MPI_INT. It is MPI_ followed by a noun with all letters capitalized\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPI SYSTEM and Communication\n",
    "\n",
    "More context here:\n",
    "\n",
    "https://www.codingame.com/playgrounds/349/introduction-to-mpi/mpi_comm_world-size-and-ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MPI_Init(&argc, &argv): Communicator set up \n",
    "\n",
    "- MPI_Comm_size(MPI_COMM_WORLD, &size): Get the number of processes\n",
    "\n",
    "- MPI_Comm_rank(MPI_COMM_WORLD, &rank): Get the rank of the process\n",
    "\n",
    "- MPI_Finalize(): Finalize the MPI environment\n",
    "\n",
    "So far we have used the default communicator only\n",
    "MPI_Comm comm = MPI_COMM_WORLD;\n",
    "But you can do much more with them, and here we just give a short introduction to those possibilities\n",
    "\n",
    "Duplicate\n",
    "\n",
    "Split\n",
    "\n",
    "Define new communicators by groups of processes\n",
    "\n",
    "Spawn new communicators (highly advanced MPI)\n",
    "\n",
    "Intercommunicate (highly advanced MPI)\n",
    "\n",
    "Duplicating\n",
    "\n",
    "- int **MPI_Comm_dup**(MPI_Comm comm, MPI_Comm *newcomm)\n",
    "\n",
    "- int **MPI_Comm_idup**(MPI_Comm comm, MPI_Comm *newcomm, MPI_Request *request)\n",
    "\n",
    "- int **MPI_Comm_free**(MPI_Comm *comm);\n",
    "\n",
    "Splitting \n",
    "\n",
    "- int **MPI_Comm_split**( MPI_Comm comm, int color, int key, MPI_Comm *newcomm)\n",
    "\n",
    "comm: communicator (handle)\n",
    "\n",
    "color: control of subset assignment (integer)\n",
    "\n",
    "key: control of rank assignment (integer)\n",
    "\n",
    "newcomm: new communicator (handle)\n",
    "\n",
    "Constructing new by groups and get group of communicators\n",
    "\n",
    "- int **MPI_Comm_group**(MPI_Comm comm, MPI_Group *group)\n",
    "\n",
    "comm : Communicator (handle)\n",
    "\n",
    "group : Group in communicator (handle)\n",
    "\n",
    "• Manipulate the groups with functions like MPI_Group_incl, MPI_Group_excl, …\n",
    "\n",
    "• Create the communicator(s) by\n",
    "\n",
    "- int **MPI_Comm_create**( MPI_Comm comm, MPI_Group group, MPI_Comm *newcomm )\n",
    "\n",
    "newcomm : new communicator (handle).\n",
    "\n",
    "- int **MPI_Group_incl**(MPI_Group group, int n, const int ranks[], MPI_Group *newgroup)\n",
    "\n",
    "group Group (handle).\n",
    "\n",
    "n Number of elements in array ranks (and size of newgroup)(integer).\n",
    "ranks Ranks of processes in group to appear in newgroup (array of\n",
    "integers)\n",
    "\n",
    "- int **MPI_Group_excl**(MPI_Group group, int n, const int ranks[], MPI_Group *newgroup)\n",
    "\n",
    "group Group (handle).\n",
    "\n",
    "n Number of elements in array ranks (integer). \n",
    "\n",
    "ranks Array of integer ranks in group not to appear in newgroup.\n",
    "\n",
    "Using groups to improve one-sided comms\n",
    "\n",
    "• Define exposure epoch, on target, and access epoch, on origin,\n",
    "epochs using process groups\n",
    "\n",
    "• Target runs exposure epoch by issuing\n",
    "\n",
    "- int **MPI_Win_post**(MPI_Group group, int assert, MPI_Win win)\n",
    "\n",
    "- int **MPI_Win_wait**(MPI_Win win)\n",
    "\n",
    "• Origin runs access epoch by issuing\n",
    "\n",
    "- int **MPI_Win_start**(MPI_Group group, int assert, MPI_Win win)\n",
    "\n",
    "- int **MPI_Win_complete**(MPI_Win win)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](SendReceive.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPI SEND CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- int **MPI_Send**(const void* buf, int count, MPI_Datatype datatype, int dest,int tag, MPI_Comm comm) \n",
    "\n",
    "- int **MPI_Ssend**(const void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm)\n",
    "\n",
    "• ”S” for “Synchronous”, meaning that the receiver is always forced to send an acknowledge. It will not avoid deadlocks. In this case, all unsafe operations should always deadlock, helping you out to debug and write “safer” code\n",
    "\n",
    "- int **MPI_Bsend**(const void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm)\n",
    "\n",
    "User is responsible for allocating large enough buffers\n",
    "\n",
    "- int **MPI_Isend**(const void *buf, int count, MPI_Datatype datatype, int dest,\n",
    "int tag, MPI_Comm comm, MPI_Request *request)\n",
    "\n",
    "Immediate or Incomplete. “Here is my data, please send it forward as I instruct” or “I am expecting certain type of data to come to this provided buffer space”.\n",
    "\n",
    "- int **MPI_Rsend**(const void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm)\n",
    "\n",
    "R for “Ready”. It is a blocking send, but it will not start until the matching receive is posted. It will not avoid deadlocks.\n",
    "\n",
    "- int **MPI_Sendrecv**(const void *sendbuf, int sendcount, MPI_Datatype sendtype,\n",
    "    int dest, int sendtag, void *recvbuf, int recvcount,\n",
    "    MPI_Datatype recvtype, int source, int recvtag,\n",
    "    MPI_Comm comm, MPI_Status *status): \n",
    "\n",
    "Sends and receives a message with the right choice of source and destination. Then you always need a “pair” to communicate with. If not, then you need to use “MPI_PROC_NULL”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPI RECEIVE CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- int **MPI_Recv**(void* buf, int count, MPI_Datatype datatype, int source,int tag, MPI_Comm comm, MPI_Status *status)\n",
    "\n",
    "- int **MPI_Irecv**(void *buf, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Request *request)\n",
    "\n",
    "Immediate or Incomplete Non-blocking routines yield an MPI_Request object. This request can then\n",
    "be used to query whether the operation has completed. MPI_Irecv routine\n",
    "does not yield an MPI_Status object. This is because the status object\n",
    "describes the actually received data, and at the completion of\n",
    "the MPI_Irecv call there is no received data yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One sided communication typical workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **MPI_Info** info;\n",
    "\n",
    "Declares an MPI_Info object.\n",
    "\n",
    "Description: MPI_Info is used to pass additional information or hints to the MPI runtime about how the communication should be optimized. It's like a set of key-value pairs. In many cases, it can just be set to MPI_INFO_NULL if no special options are needed.\n",
    "\n",
    "- **MPI_Win** window;\n",
    "\n",
    "Declares an MPI_Win object.\n",
    "\n",
    "Description: This object represents the memory window used in one-sided communication. A window is a region of memory that is made available for direct access by other processes.\n",
    "\n",
    "- int **MPI_Win_create**(void *base, MPI_Aint size, int disp_unit, MPI_Info info, MPI_Comm comm, MPI_Win *win);\n",
    "\n",
    "Allocates window segment\n",
    "\n",
    "Purpose: Creates an MPI basic window object for one-sided communication.\n",
    "\n",
    "base (pointer to) local memory to expose for RMA (remote memory access) \n",
    "\n",
    "size of a local window in bytes\n",
    "\n",
    "disp_unit local unit size for displacements in bytes\n",
    "\n",
    "info info argument\n",
    "\n",
    "comm communicator\n",
    "\n",
    "win handle to window\n",
    "\n",
    "- int **MPI_Win_create_dynamic**(MPI_Info info, MPI_Comm comm, MPI_Win *win)\n",
    "\n",
    "Similar to the others, but only a pointer to a window object, with\n",
    "its attached memory yet unspecified, is returned.\n",
    "to an empty buffer is returned. To attach memory to the Window:\n",
    "\n",
    "- **MPI_Win_attach**(MPI_Win win, void *base, MPI_Aint size)\n",
    "\n",
    "- **MPI_Win_detach**(MPI_Win win, void *base)\n",
    "\n",
    "\n",
    "- int **MPI_Win_allocate**(MPI_Aint size, int disp_unit, MPI_Info info, MPI_Comm comm, void *baseptr, MPI_Win *win)\n",
    "\n",
    "size: size of a local window in bytes\n",
    "\n",
    "disp_unit local unit size for displacements, in bytes\n",
    "\n",
    "info: info argument\n",
    "\n",
    "comm: communicator\n",
    "\n",
    "baseptr: address of local allocated window segment\n",
    "\n",
    "win: window object returned by the call\n",
    "\n",
    "- int **MPI_Win_free**(MPI_Win *win) ;\n",
    "\n",
    "Purpose: Frees the MPI window object.\n",
    "\n",
    "Description: This function is called when the window object is no longer needed. It deallocates any resources associated with the window and makes the memory region inaccessible for one-sided communication.\n",
    "\n",
    "\n",
    "Active (global) RMA synchronization: fences\n",
    "- **MPI_Win_fence** (assert, MPI_Win win)\n",
    "\n",
    "assert optimize for specific usage. Valid values are ”0”,\n",
    "MPI_MODE_NOSTORE, MPI_MODE_NOPUT,\n",
    "MPI_MODE_NOPRECEDE, MPI_MODE_NOSUCCEED\n",
    "\n",
    "win window handle\n",
    "\n",
    "• Used both starting and ending an epoch\n",
    "• Assertions with 0 will always work, but being more specific could help, see the next slide (advanced)\n",
    "\n",
    "Passive synchronization\n",
    "- int **MPI_Win_lock**(int lock_type, int rank, int assert, MPI_Win win)\n",
    "\n",
    "lock_type: Indicates whether other processes may access the target window at the same time (if MPI_LOCK_SHARED) or not (MPI_LOCK_EXCLUSIVE)\n",
    "\n",
    "rank: rank of the process having the locked (target) window\n",
    "\n",
    "assert: Used to optimize this call; zero may be used as a default.\n",
    "\n",
    "win: window object\n",
    "\n",
    "- int **MPI_Win_unlock**(int rank, MPI_Win win)\n",
    "\n",
    "\n",
    "- int **MPI_Put**(const void *origin_addr, int origin_count, MPI_Datatype\n",
    "            origin_datatype, int target_rank, MPI_Aint target_disp,\n",
    "            int target_count, MPI_Datatype target_datatype, MPI_Win win)\n",
    "\n",
    "Moving data: put\n",
    "\n",
    "The sending process writes data directly to the memory of the receiving process. The receiver does not need to post a corresponding receive.\n",
    "\n",
    "• Otherwise very normal-looking call, but the\n",
    "target data description is somewhat non-trivial\n",
    "\n",
    "• When creating a window, you need to specify the\n",
    "displacement unit (from the window start)\n",
    "\n",
    "- int **MPI_Get**(void *origin_addr, int origin_count, \n",
    "    MPI_Datatype origin_datatype, int target_rank, \n",
    "    MPI_Aint target_disp, int target_count, \n",
    "    MPI_Datatype target_datatype, MPI_Win win)\n",
    "\n",
    "Similar syntax to MPI_Put\n",
    "\n",
    "The sending process reads data directly from the memory of the receiving process. Again, the receiving process is not actively involved in the operation.\n",
    "\n",
    "- int **MPI_Accumulate**(const void *origin_addr, int origin_count,\n",
    "    MPI_Datatype origin_datatype, int target_rank,\n",
    "    MPI_Aint target_disp, int target_count,\n",
    "    MPI_Datatype target_datatype, MPI_Op op, MPI_Win win)\n",
    "\n",
    "• Store data from the origin process to the memory window of the target process and combine it using one of the predefined MPI reduction operations\n",
    "\n",
    "• Predefined operators are available (we talk about these in the connection of collectives), but no user-defined ones.\n",
    "\n",
    "• There is one extra operator: MPI_REPLACE, this has the effect that only the last result to arrive is retained.\n",
    "\n",
    "\n",
    "int **MPI_Get_accumulate**(const void *origin_addr, int\n",
    "origin_count,MPI_Datatype origin_datatype, void\n",
    "*result_addr, int result_count, MPI_Datatype result_datatype,\n",
    "int target_rank, MPI_Aint target_disp, int target_count,\n",
    "MPI_Datatype target_datatype, MPI_Op op, MPI_Win win)\n",
    "\n",
    "• Store data from target window to the origin, and combine it with the predefined\n",
    "operation.\n",
    "\n",
    "• Predefined operators are available (we talk about these in the connection of\n",
    "collectives), but no user-defined ones.\n",
    "\n",
    "• There is one extra operator: MPI_REPLACE, this has the effect that only the\n",
    "last result to arrive is retained.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collective communications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- int **MPI_Bcast**(void* buffer, int count, MPI_Datatype datatype, int root, MPI_Comm comm)\n",
    "\n",
    "Collective data movement; Broadcast\n",
    "\n",
    "These two processes are reverse of each other\n",
    "\n",
    "- int **MPI_Gather**( const void* sendbuf, int sendcount, MPI_Datatype sendtype,\n",
    "void* recvbuf, int recvcount, MPI_Datatype recvtype, int root, MPI_Comm comm)\n",
    "\n",
    "- int **MPI_Scatter** (void* sendbuf, int sendcount, MPI_Datatype sendtype,\n",
    "void* recvbuf, int recvcount, MPI_Datatype recvtype, int root, MPI_Comm comm)\n",
    "\n",
    "• Send and receive buffers are no longer of the same size, hence need to specify two buffers\n",
    "\n",
    "• Root receives/sends 𝑛𝑝 sized buffer of data, others send/receive data of the size 𝑛.\n",
    "\n",
    "• Counterintuitively, root’s recvcount/sendcount is NOT 𝑛𝑝, but 𝑛.\n",
    "\n",
    "• SPMD code; everybody will have to allocate the large buffer; is that not awkward? Yes, other than ‘root’ processes,\n",
    "\n",
    "• use a null pointer in place of the larger buffer\n",
    "\n",
    "• Or use the option “MPI_IN_PLACE” for the unnecessary buffers.\n",
    "\n",
    "- int **MPI_Allgather**(const void *sendbuf, int sendcount, MPI_Datatype sendtype,\n",
    "void *recvbuf, int recvcount, MPI_Datatype recvtype, MPI_Comm comm)\n",
    "\n",
    "- int **MPI_Iallgather**(const void *sendbuf, int sendcount, MPI_Datatype sendtype,\n",
    "void *recvbuf, int recvcount, MPI_Datatype recvtype, MPI_Comm comm, MPI_Request *request)\n",
    "\n",
    "- int **MPI_Alltoall**(const void *sendbuf, int sendcount, MPI_Datatype sendtype,\n",
    "void *recvbuf, int recvcount, MPI_Datatype recvtype, MPI_Comm comm)\n",
    "\n",
    "- int **MPI_Ialltoall**(const void *sendbuf, int sendcount, MPI_Datatype sendtype,\n",
    "void *recvbuf, int recvcount, MPI_Datatype recvtype, MPI_Comm comm, MPI_Request *request)\n",
    "\n",
    "The basic routines send/receive the same amount of data from each process\n",
    "• “v” for vector routines to allow the programmer to specify a message of different length for each destination (one-to-all) or source (all-toone) or destination and source (all-to-all)\n",
    "• May need to use some other collectives to compute the required displacements\n",
    "\n",
    "- int **MPI_Gatherv**(const void *sendbuf, int sendcount, MPI_Datatype sendtype, void *recvbuf,\n",
    "const int recvcounts[], const int displs[], MPI_Datatype recvtype, int root, MPI_Comm comm)\n",
    "\n",
    "- int **MPI_Alltoallv**(void *sendbuf, int *sendcnts, int *sdispls, MPI_Datatype sendtype,\n",
    "void *recvbuf, int *recvcnts, int *rdispls, MPI_Datatype recvtype, MPI_Comm comm)\n",
    "\n",
    "- int **MPI_Reduce**(const void *sendbuf, void *recvbuf, int count,\n",
    "MPI_Datatype datatype, MPI_Op op, int root, MPI_Comm comm)\n",
    "\n",
    "- int **MPI_Ireduce**(const void *sendbuf, void *recvbuf, int count,\n",
    "MPI_Datatype datatype, MPI_Op op, int root, MPI_Comm comm, MPI_Request *request)\n",
    "\n",
    "- int **MPI_Allreduce**(const void* sendbuf, void* recvbuf, int count,\n",
    "MPI_Datatype datatype, MPI_Op op, MPI_Comm comm)\n",
    "\n",
    "- int **MPI_Iallreduce**(const void *sendbuf, void *recvbuf, int count,\n",
    "MPI_Datatype datatype, MPI_Op op, MPI_Comm comm, MPI_Request *request)\n",
    "\n",
    "- int **MPI_Scan**(const void *sendbuf, void *recvbuf, int count, MPI_Datatype datatype, MPI_Op op,\n",
    "MPI_Comm comm)\n",
    "\n",
    "- int **MPI_Iscan**(const void *sendbuf, void *recvbuf, int count, MPI_Datatype datatype, MPI_Op op,\n",
    "MPI_Comm comm, MPI_Request *request)\n",
    "\n",
    "- int **MPI_Exsca**(const void *sendbuf, void *recvbuf, int count, MPI_Datatype datatype, MPI_Op op,\n",
    "MPI_Comm comm)\n",
    "\n",
    "- int **MPI_Iexscan**(const void *sendbuf, void *recvbuf, int count, MPI_Datatype datatype, MPI_Op op,\n",
    "MPI_Comm comm, MPI_Request *request)\n",
    "\n",
    "- int **MPI_Reduce_scatter**(const void *sendbuf, void *recvbuf, const int recvcounts[],MPI_Datatype\n",
    "datatype, MPI_Op op, MPI_Comm comm)\n",
    "\n",
    "- int **MPI_Ireduce_scatter**(const void *sendbuf, void *recvbuf, const int recvcounts[],MPI_Datatype\n",
    "datatype, MPI_Op op, MPI_Comm comm, MPI_Request *request)\n",
    "\n",
    "MPI_Op takes these values:\n",
    "\n",
    "MPI type meaning applies to\\\n",
    "\n",
    "MPI_MAX maximum integer, floating point\n",
    "\n",
    "MPI_MIN minimum\n",
    "\n",
    "MPI_SUM sum integer, floating point, complex, multilanguage types\n",
    "\n",
    "MPI_REPLACE overwrite\n",
    "\n",
    "MPI_NO_OP no change\n",
    "\n",
    "MPI_PROD product\n",
    "\n",
    "MPI_LAND logical and C integer, logical\n",
    "\n",
    "MPI_LOR logical or\n",
    "\n",
    "MPI_LXOR logical xor\n",
    "\n",
    "MPI_BAND bitwise and integer, byte, multilanguage types\n",
    "\n",
    "MPI_BOR bitwise or\n",
    "\n",
    "MPI_BXOR bitwise xor\n",
    "\n",
    "MPI_MAXLOC max value and location MPI_DOUBLE_INT and such\n",
    "\n",
    "MPI_MINLOC min value and location\n",
    "\n",
    "User defined operation\n",
    "\n",
    "- int **MPI_Op_create**(MPI_User_function *function, int commute, MPI_Op *op)\n",
    "\n",
    "Prototype \n",
    "\n",
    "- typedef void **MPI_User_function**(void *invec, void *inoutvec, int *len,\n",
    "MPI_Datatype *datatype);\n",
    "\n",
    "inoutvec[i] = invec[i] op inoutvec[i] from i=0;len-1\n",
    "\n",
    "• The operation is assumed to be associative\n",
    "\n",
    "• You can use flag “commute” to indicate whether the function is in\n",
    "addition commutative or not.\n",
    "\n",
    "• Void return as no errors are expected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syncronization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "int **MPI_Barrier**(MPI_Comm comm)\n",
    "\n",
    "int **MPI_Ibarrier**(MPI_Comm comm, MPI_Request *request)\n",
    "\n",
    "• Waits until all processes have called it\n",
    "\n",
    "• Forces time synchronization\n",
    "\n",
    "• Not needed very often, as collectives impose synchronization on their own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User defined data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining and decommissioning a new datatype\n",
    "\n",
    "- int **MPI_Type_contiguous**(int count,MPI_Datatype oldtype, MPI_Datatype *newtype)\n",
    "\n",
    "- int **MPI_Type_XXX**(…MPI_Datatype oldtype, MPI_Datatype *newtype)\n",
    "\n",
    "- int **MPI_Type_commit**(MPI_Datatype *newtype)…\n",
    "\n",
    "- int **MPI_Type_free**(MPI_Datatype *newtype)\n",
    "\n",
    "- int **MPI_Type_vector**(int count, int blocklength, int stride, MPI_Datatype oldtype, MPI_Datatype *newtype)\n",
    "\n",
    "count number of blocks\n",
    "\n",
    "blocklength number of replicated oldtype elements in each block\n",
    "\n",
    "stride total number of elements in each block\n",
    "\n",
    "newtype the new datatype to commit, use, and decommission\n",
    "\n",
    "oldtype the datatype to use for constructing newtype\n",
    "\n",
    "count number of replicas\n",
    "\n",
    "XXX stands for one of the constructors\n",
    "\n",
    "- int **MPI_Type_create_subarray**(int ndims, const int sizes[], const int subsizes[], \n",
    "const int offsets[], int order, MPI_Datatype oldtype, MPI_Datatype *newtype)\n",
    "\n",
    "ndims number of array dimensions\n",
    "\n",
    "sizes number of array elements in each dimension\n",
    "\n",
    "subsizes number of subarray elements in each dimension\n",
    "\n",
    "offsets starting point of subarray in each dimension\n",
    "\n",
    "order storage order of the array. Either MPI_ORDER_C or MPI_ORDER_FORTRAN\n",
    "\n",
    "---\n",
    "\n",
    "Datatype constructors Datatype constructors\n",
    "\n",
    "MPI_Type_contiguous contiguous datatypes\n",
    "\n",
    "MPI_Type_vector regularly spaced datatype\n",
    "\n",
    "MPI_Type_indexed variably spaced datatype\n",
    "\n",
    "MPI_Type_create_subarray subarray within a multi-dimensional array\n",
    "\n",
    "MPI_Type_create_hvector like vector, but uses bytes for spacings\n",
    "\n",
    "MPI_Type_create_hindexed like index, but uses bytes for spacings\n",
    "\n",
    "MPI_Type_create_struct fully general datatype\n",
    "\n",
    "newtype the new datatype to commit, use, and\n",
    "decommission\n",
    "oldtype the datatype to use for constructing newtype\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cartesian grid topology\n",
    "\n",
    "- int **MPI_Cart_create**( MPI_Comm comm_old, int ndims, const int\n",
    "dims, const int periods, int reorder, MPI_Comm *comm_cart);\n",
    "\n",
    "- int **MPI_Cart_coords**( MPI_Comm comm, int rank, int maxdims, int coords);\n",
    "\n",
    "- int **MPI_Cart_rank**( MPI_Comm comm, init coords, int *rank);\n",
    "\n",
    "ndims f.ex. 2 for 2-dim, 3 for 3-dim\n",
    "\n",
    "dims of grid in each ndim (size of ndim)\n",
    "\n",
    "periods which of the boundaries are periodic?\n",
    "\n",
    "reorder can MPI re-order ranks as to what it sees optimal?\n",
    "\n",
    "coords Coordinate of the process in the Cartesian topology\n",
    "\n",
    "rank the rank of the process in the Cartesian topology\n",
    "\n",
    "- int **MPI_Cart_shift**(MPI_Comm comm, int direction, int displ, int *source, int *dest)\n",
    "\n",
    "Determine the neighbors for communication\n",
    "\n",
    "direction Shifting direction in the defined dim\n",
    "\n",
    "displ displacement in ranks >0 for up <0 down in the direction\n",
    "\n",
    "source Neighbor rank in decreasing index\n",
    "\n",
    "dest Neighbor rank towards increasing index\n",
    "\n",
    "“Names” of the neighbor ranks come from MPI_Sendrecv, in the context of which this routine is often used\n",
    "\n",
    "- int **MPI_Dist_graph_create_adjacent**(MPI_Comm oldcomm, int indegree, int sources[], int sourceweights[],\n",
    "int outdegree, int dests[], int destweights[], MPI_Info info, int reorder, MPI_Comm *newcomm)\n",
    "\n",
    "indegree : number of source nodes; \n",
    "\n",
    "sources : array containing the ranks of the source nodes; \n",
    "\n",
    "sourceweights : weights for source to destination edges or MPI_UNWEIGHTED; \n",
    "\n",
    "outdegree : array specifying the number of destinations, \n",
    "\n",
    "dests : ranks of the destination nodes, \n",
    "\n",
    "destweights : weights for destination to source edges or MPI_UNWEIGHTED; \n",
    "\n",
    "info : hints on optimization and interpretation of weights\n",
    "\n",
    "reorder : the process may be reordered?\n",
    "\n",
    "- int **MPI_Dist_graph_create**(MPI_Comm comm_old, int n, const int sources[], const int degrees[], const int destinations[], const int weights[], MPI_Info info, int reorder, MPI_Comm *comm_dist_graph)\n",
    "\n",
    "n: number of source nodes; sources : array containing the ranks of the\n",
    "source nodes; \n",
    "\n",
    "degrees : array specifying the number of destinations for\n",
    "each source node, \n",
    "\n",
    "destinations : ranks of the destination nodes,\n",
    "\n",
    "weights : weights for destination to source edges or\n",
    "MPI_UNWEIGHTED; \n",
    "\n",
    "info : hints on optimization and interpretation of\n",
    "weights, \n",
    "\n",
    "reorder : the process may be reordered?\n",
    "\n",
    "- int **MPI_Dist_graph_neighbors**(MPI_Comm comm, int maxindegree, int sources[],\n",
    "int sourceweights[], int maxoutdegree, int destinations[], int destweights[])\n",
    "\n",
    "- int **MPI_Dist_graph_neighbors_count**(MPI_Comm comm, int *indegree, int *outdegree, int *weighted)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
